{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6645a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format=\"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b0aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "seed=1234\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d69fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As usual, define some paths first to make life simpler\n",
    "training_data = Path('./data/training/training/') \n",
    "validation_data = Path('./data/validation/validation/') \n",
    "labels_path = Path('./data/monkey_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f45faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Latin Name</th>\n",
       "      <th>Common Name</th>\n",
       "      <th>Train Images</th>\n",
       "      <th>Validation Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n0</td>\n",
       "      <td>alouatta_palliata</td>\n",
       "      <td>mantled_howler</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n1</td>\n",
       "      <td>erythrocebus_patas</td>\n",
       "      <td>patas_monkey</td>\n",
       "      <td>139</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n2</td>\n",
       "      <td>cacajao_calvus</td>\n",
       "      <td>bald_uakari</td>\n",
       "      <td>137</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n3</td>\n",
       "      <td>macaca_fuscata</td>\n",
       "      <td>japanese_macaque</td>\n",
       "      <td>152</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n4</td>\n",
       "      <td>cebuella_pygmea</td>\n",
       "      <td>pygmy_marmoset</td>\n",
       "      <td>131</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n5</td>\n",
       "      <td>cebus_capucinus</td>\n",
       "      <td>white_headed_capuchin</td>\n",
       "      <td>141</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>n6</td>\n",
       "      <td>mico_argentatus</td>\n",
       "      <td>silvery_marmoset</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>n7</td>\n",
       "      <td>saimiri_sciureus</td>\n",
       "      <td>common_squirrel_monkey</td>\n",
       "      <td>142</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>n8</td>\n",
       "      <td>aotus_nigriceps</td>\n",
       "      <td>black_headed_night_monkey</td>\n",
       "      <td>133</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>n9</td>\n",
       "      <td>trachypithecus_johnii</td>\n",
       "      <td>nilgiri_langur</td>\n",
       "      <td>132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label             Latin Name                Common Name  Train Images  \\\n",
       "0    n0      alouatta_palliata             mantled_howler           131   \n",
       "1    n1     erythrocebus_patas               patas_monkey           139   \n",
       "2    n2         cacajao_calvus                bald_uakari           137   \n",
       "3    n3         macaca_fuscata           japanese_macaque           152   \n",
       "4    n4        cebuella_pygmea             pygmy_marmoset           131   \n",
       "5    n5        cebus_capucinus      white_headed_capuchin           141   \n",
       "6    n6        mico_argentatus           silvery_marmoset           132   \n",
       "7    n7       saimiri_sciureus     common_squirrel_monkey           142   \n",
       "8    n8        aotus_nigriceps  black_headed_night_monkey           133   \n",
       "9    n9  trachypithecus_johnii             nilgiri_langur           132   \n",
       "\n",
       "   Validation Images  \n",
       "0                 26  \n",
       "1                 28  \n",
       "2                 27  \n",
       "3                 30  \n",
       "4                 26  \n",
       "5                 28  \n",
       "6                 26  \n",
       "7                 28  \n",
       "8                 27  \n",
       "9                 26  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_info = []\n",
    "\n",
    "# Read the file\n",
    "lines = labels_path.read_text().strip().splitlines()[1:]\n",
    "for line in lines:\n",
    "    line = line.split(',')\n",
    "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
    "    line[3], line[4] = int(line[3]), int(line[4])\n",
    "    line = tuple(line)\n",
    "    labels_info.append(line)\n",
    "    \n",
    "# Convert the data into a pandas dataframe\n",
    "labels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n",
    "                                                 'Train Images', 'Validation Images'], index=None)\n",
    "# Sneak peek \n",
    "labels_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d6de1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'mantled_howler', 1: 'patas_monkey', 2: 'bald_uakari', 3: 'japanese_macaque', 4: 'pygmy_marmoset', 5: 'white_headed_capuchin', 6: 'silvery_marmoset', 7: 'common_squirrel_monkey', 8: 'black_headed_night_monkey', 9: 'nilgiri_langur'}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to map the labels to integers\n",
    "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
    "\n",
    "# map labels to common names\n",
    "names_dict = dict(zip(labels_dict.values(), labels_info[\"Common Name\"]))\n",
    "print(names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd95e9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traininng samples:  1096\n",
      "Number of validation samples:  272\n",
      "\n",
      "                                  image  label\n",
      "0  data\\training\\training\\n0\\n0134.jpg      0\n",
      "1  data\\training\\training\\n3\\n3024.jpg      3\n",
      "2  data\\training\\training\\n9\\n9141.jpg      9\n",
      "3  data\\training\\training\\n3\\n3060.jpg      3\n",
      "4  data\\training\\training\\n0\\n0150.jpg      0 \n",
      "\n",
      "=================================================================\n",
      "\n",
      "\n",
      "                                      image  label\n",
      "0   data\\validation\\validation\\n2\\n218.jpg      2\n",
      "1  data\\validation\\validation\\n3\\n3013.jpg      3\n",
      "2  data\\validation\\validation\\n2\\n2011.jpg      2\n",
      "3   data\\validation\\validation\\n6\\n608.jpg      6\n",
      "4   data\\validation\\validation\\n6\\n605.jpg      6\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe for the training dataset\n",
    "train_df = []\n",
    "for folder in os.listdir(training_data):\n",
    "    # Define the path to the images\n",
    "    imgs_path = training_data / folder\n",
    "    \n",
    "    # Get the list of all the images stored in that directory\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    \n",
    "    # Store each image path and corresponding label \n",
    "    for img_name in imgs:\n",
    "        train_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# Creating dataframe for validation data in a similar fashion\n",
    "valid_df = []\n",
    "for folder in os.listdir(validation_data):\n",
    "    imgs_path = validation_data / folder\n",
    "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
    "    for img_name in imgs:\n",
    "        valid_df.append((str(img_name), labels_dict[folder]))\n",
    "\n",
    "        \n",
    "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
    "# shuffle the dataset \n",
    "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "# How many samples do we have in our training and validation data?\n",
    "print(\"Number of traininng samples: \", len(train_df))\n",
    "print(\"Number of validation samples: \", len(valid_df))\n",
    "\n",
    "# sneak peek of the training and validation dataframes\n",
    "print(\"\\n\",train_df.head(), \"\\n\")\n",
    "print(\"=================================================================\\n\")\n",
    "print(\"\\n\", valid_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69815e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some constants(not truly though!) \n",
    "\n",
    "# dimensions to consider for the images\n",
    "img_rows, img_cols, img_channels = 224,224,3\n",
    "\n",
    "# batch size for training  \n",
    "batch_size=8\n",
    "\n",
    "# total number of classes in the dataset\n",
    "nb_classes=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc1f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence \n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b413a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, batch_size, is_validation_data=False):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    nb_batches = int(np.ceil(n/batch_size))\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "    \n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
    "    \n",
    "    while True:\n",
    "        if not is_validation_data:\n",
    "            # shuffle indices for the training data\n",
    "            np.random.shuffle(indices)\n",
    "            \n",
    "        for i in range(nb_batches):\n",
    "            # get the next batch \n",
    "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            # process the next batch\n",
    "            for j, idx in enumerate(next_batch_indices):\n",
    "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                label = data.iloc[idx][\"label\"]\n",
    "                \n",
    "                if not is_validation_data:\n",
    "                    img = seq.augment_image(img)\n",
    "                \n",
    "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
    "                batch_data[j] = img\n",
    "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
    "            \n",
    "            batch_data = preprocess_input(batch_data)\n",
    "            yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd8197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data generator \n",
    "train_data_gen = data_generator(train_df, batch_size)\n",
    "\n",
    "# validation data generator \n",
    "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3995a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function that returns the base model\n",
    "def get_base_model():\n",
    "    base_model = VGG16(\n",
    "        input_shape=(img_rows, img_cols, img_channels),\n",
    "        weights='imagenet',\n",
    "        include_top=True)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5197e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " drop2 (Dropout)             (None, 4096)              0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 10)                40970     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134301514 (512.32 MB)\n",
      "Trainable params: 40970 (160.04 KB)\n",
      "Non-trainable params: 134260544 (512.16 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the base model\n",
    "base_model = get_base_model()\n",
    "\n",
    "#  get the output of the second last dense layer \n",
    "base_model_output = base_model.layers[-2].output\n",
    "\n",
    "# add new layers \n",
    "x = Dropout(0.7,name='drop2')(base_model_output)\n",
    "output = Dense(10, activation='softmax', name='fc3')(x)\n",
    "\n",
    "# define a new model \n",
    "model = Model(base_model.input, output)\n",
    "\n",
    "# Freeze all the base model layers \n",
    "for layer in base_model.layers[:-1]:\n",
    "    layer.trainable=False\n",
    "\n",
    "# compile the model and check it \n",
    "optimizer = RMSprop(0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e024772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# always user earlystopping\n",
    "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# checkpoint to save model\n",
    "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
    "\n",
    "# number of training and validation steps for training and validation\n",
    "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
    "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))\n",
    "\n",
    "# number of epochs \n",
    "nb_epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea279abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joe\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:3368: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  augmenter_active = np.zeros((nb_rows, len(self)), dtype=np.bool)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# train the model \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_train_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_data_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnb_valid_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchkpt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[9], line 29\u001b[0m, in \u001b[0;36mdata_generator\u001b[1;34m(data, batch_size, is_validation_data)\u001b[0m\n\u001b[0;32m     26\u001b[0m label \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_validation_data:\n\u001b[1;32m---> 29\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img, (img_rows, img_cols))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     32\u001b[0m batch_data[j] \u001b[38;5;241m=\u001b[39m img\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:771\u001b[0m, in \u001b[0;36mAugmenter.augment_image\u001b[1;34m(self, image, hooks)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m image\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], (\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected image to have shape (height, width, [channels]), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (image\u001b[38;5;241m.\u001b[39mshape,))\n\u001b[0;32m    770\u001b[0m iabase\u001b[38;5;241m.\u001b[39m_warn_on_suspicious_single_image_shape(image)\n\u001b[1;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:822\u001b[0m, in \u001b[0;36mAugmenter.augment_images\u001b[1;34m(self, images, parents, hooks)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;124;03m\"\"\"Augment a batch of images.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    819\u001b[0m \n\u001b[0;32m    820\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    821\u001b[0m iabase\u001b[38;5;241m.\u001b[39m_warn_on_suspicious_multi_image_shapes(images)\n\u001b[1;32m--> 822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_batch_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mUnnormalizedBatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimages_aug\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:641\u001b[0m, in \u001b[0;36mAugmenter.augment_batch_\u001b[1;34m(self, batch, parents, hooks)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _maybe_deterministic_ctx(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch_inaug\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m--> 641\u001b[0m         batch_inaug \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_augment_batch_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_inaug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# revert augmentables being set to None for non-activated augmenters\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m set_to_none:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:3395\u001b[0m, in \u001b[0;36mSomeOf._augment_batch_\u001b[1;34m(self, batch, random_state, parents, hooks)\u001b[0m\n\u001b[0;32m   3386\u001b[0m augmenter_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_augmenter_order(random_state)\n\u001b[0;32m   3388\u001b[0m \u001b[38;5;66;03m# create an array of active augmenters per image\u001b[39;00m\n\u001b[0;32m   3389\u001b[0m \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;66;03m#  [[0, 0, 1],\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3393\u001b[0m \u001b[38;5;66;03m# would signal, that augmenter 3 is active for the first image,\u001b[39;00m\n\u001b[0;32m   3394\u001b[0m \u001b[38;5;66;03m# augmenter 1 and 3 for the 2nd image and augmenter 1 for the 3rd.\u001b[39;00m\n\u001b[1;32m-> 3395\u001b[0m augmenter_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_augmenter_active\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnb_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3396\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3398\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m augmenter_index \u001b[38;5;129;01min\u001b[39;00m augmenter_order:\n\u001b[0;32m   3399\u001b[0m     active \u001b[38;5;241m=\u001b[39m augmenter_active[:, augmenter_index]\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\imgaug\\augmenters\\meta.py:3368\u001b[0m, in \u001b[0;36mSomeOf._get_augmenter_active\u001b[1;34m(self, nb_rows, random_state)\u001b[0m\n\u001b[0;32m   3366\u001b[0m nn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_n(nb_rows, random_state)\n\u001b[0;32m   3367\u001b[0m nn \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mmin\u001b[39m(n, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m nn]\n\u001b[1;32m-> 3368\u001b[0m augmenter_active \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((nb_rows, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)), dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m)\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_idx, n_true \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(nn):\n\u001b[0;32m   3370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_true \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "history1 = model.fit(train_data_gen, \n",
    "                              epochs=nb_epochs, \n",
    "                              steps_per_epoch=nb_train_steps, \n",
    "                              validation_data=valid_data_gen, \n",
    "                              validation_steps=nb_valid_steps,\n",
    "                              callbacks=[es,chkpt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7215ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the loss and accuracy \n",
    "\n",
    "# get the training and validation accuracy from the history object\n",
    "train_acc = history1.history['acc']\n",
    "valid_acc = history1.history['val_acc']\n",
    "\n",
    "# get the loss\n",
    "train_loss = history1.history['loss']\n",
    "valid_loss = history1.history['val_loss']\n",
    "\n",
    "# get the number of entries\n",
    "xvalues = np.arange(len(train_acc))\n",
    "\n",
    "# visualize\n",
    "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].plot(xvalues, train_loss)\n",
    "ax[0].plot(xvalues, valid_loss)\n",
    "ax[0].set_title(\"Loss curve\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].legend(['train', 'validation'])\n",
    "\n",
    "ax[1].plot(xvalues, train_acc)\n",
    "ax[1].plot(xvalues, valid_acc)\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].legend(['train', 'validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the final loss and accuracy on our validation data?\n",
    "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
    "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
